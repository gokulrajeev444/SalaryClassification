# -*- coding: utf-8 -*-
"""Salary Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16X_SDzMzrpuJ3CZS1LBnIJLUB9KfWujL
"""

#pip install pyspark

import pandas as pd
from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_predict
import pandas as pd
import numpy as np
import pyspark
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, classification_report
#from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import plot_confusion_matrix
from imblearn.over_sampling import SMOTE 
#from sklearn.preprocessing import RobustScaler
import pandas as pd
from sklearn.preprocessing import LabelEncoder , MinMaxScaler
import matplotlib.pyplot as plt
import seaborn as sns 
from pyspark.sql import SparkSession
from pyspark.sql.functions import sum,avg,max,count
from pyspark.sql.functions import col, asc,desc
import plotly.express as px
import math   
from sklearn.feature_selection import mutual_info_regression

"""Creating the spark session



"""

spark = SparkSession.builder.master("local[*]").getOrCreate()
spark.conf.set("spark.sql.repl.eagerEval.enabled", True) # Property used to format output tables better
spark

#present working directory

pwd

sparkDF=spark.read.option("delimiter", ",").option("header",True).option("inferSchema",True).csv("salary.csv")

print("The columns are   ",sparkDF.columns)

""" 
 *Printing all the unique rows*
"""

for i in sparkDF.columns:
    print("The count for each category in the attribute::: \n\n"+i)
    sparkDF.groupBy(i).agg(count("*").alias("count_of_each")).orderBy(col("count_of_each").desc()).show()
    print("\n\n\n")

"""*converting Spark dataframe to pandas Dataframe*"""

df=sparkDF.toPandas()
df.shape

"""*Printing unique rows (pandas)*"""

for col in df.columns.values:
    print('__'+col+'__', end="*\n\n")
    print(df[col].unique(), end="\n\n ~~\n")

"""# **Preprocessing**

"""

df.salary.unique()

## calculating null
print("Before converting '?' to null- \n\n",df.isnull().sum())
df['workclass'] = df['workclass'].replace(' ?', np.nan)
df['occupation'] = df['occupation'].replace(" ?", np.nan)
df['native-country'] = df['native-country'].replace(" ?", np.nan)

"""---
---
Geting the most frequent workclass and most frequent occupation in that class





"""

print("The most frequent workclass is ",df['workclass'].mode())
temp = df['occupation'][df['workclass']==' Private']
print("Most frequent occupation in the workclass ", df['workclass'].mode(), 'is ',temp.mode())

"""---
---
 Imputing the null values with the most frequent 
"""

df['workclass'].fillna(df['workclass'].mode()[0], inplace=True)
df['workclass'].isnull().sum()
df['occupation'].fillna(' Craft-repair', inplace=True)
df['occupation'].isnull().sum()


#most Frequent native-country
df['native-country'].fillna(df['native-country'].mode()[0], inplace=True)
df['native-country'].isnull().sum()

print("\n\nAfter converting '?' to null- \n\n",df.isnull().sum())

"""---
---



*Deleting duplicate rows*
"""

print("Total number of duplicate rows are ",df.duplicated().sum())
df.drop_duplicates(keep='first',inplace=True)

df.duplicated().sum()

df

"""# **Exploratory data analysis**

---
---



*AGE Distribution*
"""

sns.displot(data=df, x="age", hue="salary", kind="kde", height=4, aspect=3)

"""---
---



*hours-per-week distribution for the two classes of salary*
"""

sns.displot(data=df, x="hours-per-week", hue="salary", kind="kde", height=4, aspect=3)

"""---
---
"""

sns.displot(data=df, x="fnlwgt", hue="salary", kind="kde", height=4, aspect=2)

"""We understand that the final weight(number of people the census believes the entry represents) has a skewed data. We would be using oversampling

---
---

*Workclass Distribution*
"""

plt.figure(figsize=(13,5))
df.workclass.value_counts().plot(kind="bar", color="blue")
plt.xlabel("Workclass")
plt.tight_layout()
plt.show()

"""---
---
Comparing education vs Education-num
"""

plt.figure(figsize=(13,4))
df['education'].value_counts().plot(kind='bar', color = "grey")
plt.xlabel("Education")
plt.show()

plt.figure(figsize=(13,4))
df['education-num'].value_counts().plot(kind='bar', color = "pink")
plt.xlabel("Education-num")
plt.show()

"""We understand that both education and education-num are the same. Education-num is a higher for a higher educated person. So we dont have to convert education into categorical data using labelEncoding. We can use education-num directly and drop education.

---
---
*Distribution education-num *
"""

sns.displot(data=df, x="education-num", hue="salary", kind="kde", height=6.5, aspect=3)

"""---
---
Total distribution of education-num 
"""

sns.histplot(data=df, x="education-num")

"""---
---
Function for the getting percentage distribution for different categories
"""

def getBarPercent (plot, feature):
    total = len(feature)
    for p in ax.patches:
        percentage = '{:.0f}%'.format(100 * p.get_height()/total)
        x = p.get_x() + p.get_width() / 2 - 0.05
        y = p.get_y() + p.get_height()
        ax.annotate(percentage, (x, y), size = 12)
    plt.show()

plt.figure(figsize=(6,4))
ax = sns.countplot( x=df.salary , data= df , palette='viridis')
ax.set_title('Salaries ratio for all persons')
getBarPercent(ax , df.salary)

"""We would have to handle this unbalanced Data

---
---
*Male vs Female distribution of salary*
"""

plt.figure(figsize=(5,3))
sns.countplot(data=df, x='sex', hue='salary', palette='viridis').set_title('Salaries ratio for Male/Female')

"""---
---
*Distribution of salaries for different  for races
"""

plt.figure(figsize=(14, 5))
ax = sns.countplot(data=df,y='race', hue='salary')
sns.set_palette('Accent_r')
ax.set_title('Race VS Salary')

"""We can see that the total data is from race of white in general. Our results might be skewed if we use race for the machine learning."""

df.columns

"""---
---
*Bar plot for various Workclasses in the 2 salary cateogories*
"""

plt.figure(figsize=(30,6))
sns.countplot(data=df, x='workclass', hue='salary' ).set_title('Salaries ratio for Occupation')

"""---
---
*Bar plot for various occupations in the 2 salary cateogories*
"""

plt.figure(figsize=(30,6))
sns.countplot(data=df, x='occupation', hue='salary' ).set_title('Salaries ratio for Occupation')

"""we see that some occupations have salary less than 50k for majority of the peoplecraft-repair, adm-clerical). Some have an equal distribution of more and less than 50k salaried people like exec-managerial and prof-speciality.

---
---
*Bar plot for various relationship in the 2 salary cateogories*
"""

plt.figure(figsize=(12,6))
sns.countplot(data=df, x='relationship', hue='salary' ).set_title('Salaries ratio for Occupation')

"""Since the Husband/wife is having more equal distribution of salary, we will be moving that into label encoding value 1 and all the others as 0."""

df_cleaned=df

df

"""## Feature Engineering

---
---
*Converting target variable to binary value*
"""

df['salary'] = df['salary'].map({' >50K': 1, ' <=50K': 0})
X = df.iloc[:, 0:-1]
y = df.iloc[:, -1]
X['native-country'].value_counts().sort_values(ascending=False).head(20)

#Find relationship
def get_mutual_information_score(X, y):
    X1 = X.copy()
    # Target variable y discrete
    for i in X1.select_dtypes('object').columns:
        X1[i], _ = X1[i].factorize()
    mi_score = mutual_info_regression(X1, y)
    return pd.Series(mi_score, name='MI Score', index=X1.columns).sort_values(ascending=False)

#categorical Data
def one_hot_encoding_field(dataset, field_name):
    field_one_hot = pd.get_dummies(X[field_name], prefix=f"{field_name}=", prefix_sep="")
    dataset = pd.concat([X, field_one_hot], axis=1)
    dataset = dataset.drop([field_name], axis=1)
    return dataset

#normalizing so that some fields with higher integer values dont unnecessarily skew the model
def normalization_of_numerical(dataset, field_name):
    X[field_name] = X[field_name] / X[field_name].max()
    return X

print(get_mutual_information_score(X, y))

"""#### encoding native-country"""

most_frequent_10 = [x for x in X['native-country'].value_counts().sort_values(ascending=False).head(10).index]
most_frequent_10
for i in most_frequent_10:
  print(i)
  X[i]=np.where(X['native-country']==i,1,0)

# Onehot encoding mapping result
X[['native-country']+most_frequent_10]

"""#### encoding marital-status"""

X['marital-status'].value_counts()

X['marital-status']=X['marital-status'].replace([' Married-civ-spouse',' Married-spouse-absent',' Married-AF-spouse'],1)
X['marital-status']=X['marital-status'].replace([' Divorced',' Separated',' Widowed'],0)
X['marital-status']=X['marital-status'].replace([' Never-married'],-1)
X['marital-status'].value_counts()

"""#### Encoding relationship

"""

X['relationship']=X['relationship'].replace([' Husband',' Wife'],1)
X['relationship']=X['relationship'].replace([' Not-in-family',' Unmarried',' Own-child', ' Other-relative'],0)

X['relationship'].value_counts()

### Normalizinng fucntion, onehot encoding function and MutualInformation function

X.head(3)

#normalizing so that some fields with higher integer values dont unnecessarily skew the model
numerical_fields_for_normalization = ["age", "fnlwgt", "education-num", "capital-gain", "capital-loss", "hours-per-week"]

nominal_fields_for_one_hot_encoding=["workclass","occupation","sex","race"]

y

#dropping native-country as if its encoded.

X.drop('native-country', axis=1, inplace=True)

#dropping education as there is an exact mirror field education-num
X.drop('education', axis=1, inplace=True)

X.head(5)

for i in numerical_fields_for_normalization:
    X = normalization_of_numerical(X, i)

#normalizing numerical attributes so that they are equally scaled
for j in nominal_fields_for_one_hot_encoding:
    X = one_hot_encoding_field(X, j)

X

"""#### smote sampling

"""

smote=SMOTE(random_state=42)
X, y = smote.fit_resample(X, y)

fig = px.pie(values=y.value_counts(), width=1000, height=300, title="Data Balance")



fig.show()

"""## Modelling

---
---
*Initializing the 4 models*
"""

decisionTree=DecisionTreeClassifier()
logR = LogisticRegression(random_state=0, max_iter=X.shape[0])
knn = KNeighborsClassifier(n_neighbors=4)
randomModel = RandomForestClassifier()

cross_val_score_decision_tree=cross_val_score(decisionTree,X,y,cv=10,scoring='accuracy').mean()

cross_val_score_KNN=cross_val_score(knn,X,y,cv=10,scoring='accuracy').mean()

cross_val_score_logR=cross_val_score(logR,X,y,cv=10,scoring='accuracy').mean()

cross_val_score_random_forest=cross_val_score(randomModel,X,y,cv=10,scoring='accuracy').mean()

print("The accuracy of Decision Tree accuracy ",cross_val_score_decision_tree)
print("Logistic Regression accuracy ",cross_val_score_logR)
print("KNN accuracy ",cross_val_score_KNN)
print("Random forest accuracy ",cross_val_score_random_forest)

### cross validation prediction

# y_pred_decision_tree = cross_val_predict(decisionTree, X, y, cv=10)
# y_pred_knn = cross_val_predict(knn, X, y, cv=10)
# y_pred_random_logR = cross_val_predict(logR, X, y, cv=10)
# y_pred_random_model = cross_val_predict(randomModel, X, y, cv=10)



"""---
---
*Function for model Evaluation*
"""

from sklearn import metrics
def model_evaluation(modeName, x_val, y_val):
  #plot_confusion_matrix(modeName,x_val,y_val) // deprecated
  print("\n\n The model evaluation metrics : \n\n")
  prediction=modeName.predict(x_val)
  print("Accuracy of the model is ",metrics.accuracy_score(y_val,prediction))
  print("Recall of the model is ",metrics.recall_score(y_val,prediction))
  print("Precision of the model is ",metrics.precision_score(y_val,prediction))
  print("F1 Score of the model is ",metrics.f1_score(y_val,prediction))
  print("\n\n\n")
  cm=confusion_matrix(y_val,prediction)
  print("\n\n\n")
  plt.figure(figsize = (6,6))
  sns.heatmap(cm, annot=True, cmap= 'flare',  fmt='d', cbar=True)
  plt.xlabel('Predicted_Label')
  plt.ylabel('Truth_Label')
  plt.title('The Confusion Matrix - ')

"""---
---
 *Split the data into test and validation sets*
"""

X_train,X_validaiton, y_train, y_validation=train_test_split(X,y, test_size=0.2 ,shuffle=True, random_state=10)
model_RF=randomModel.fit(X_train,y_train)
#y_pred_random_model = model_RF.predict(X_validaiton)

# Model Evaluation for the most acuurate model
model_evaluation(model_RF,X_validaiton,y_validation)

"""## Deep learning

"""

from keras.layers import Dense
from keras.models import Sequential

dimensions=X_train.shape

model_dnn = Sequential()
model_dnn.add(Dense(32, activation='relu', input_dim=dimensions[1]))
model_dnn.add(Dense(16, activation='relu'))
model_dnn.add(Dense(16, activation='relu'))

# since this is a classification project, output layer activation function is Sigmoid
model_dnn.add(Dense(1, activation='sigmoid'))
model_dnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

dnn=model_dnn.fit(X_train, y_train, epochs=200, verbose=False)

accuracy_score_dnn_train_data=model_dnn.evaluate(X_train,y_train, verbose=False)
accuracy_score_dnn_test_data=test_score_dnn=model_dnn.evaluate(X_validaiton,y_validation, verbose=False)

print("\nAccuracy on the training dataset is: %.2f%%\n" % (accuracy_score_dnn_train_data[1]*100))
print("\n\nAccuracy on the testing dataset is: %.2f%%\n" % (accuracy_score_dnn_test_data[1]*100))

p_pred=model_dnn.predict(X_validaiton)
#p_pred = p_pred.flatten()
#prediction_dnn = np.where(p_pred > 0.5, 1, 0)

print(p_pred.round(2))

dnn_c_matrix = confusion_matrix(y_validation, np.round(p_pred))
ax = sns.heatmap(dnn_c_matrix, annot=True, xticklabels=['Less than 50k', 'More than 50k'], yticklabels=['Less than 50k', 'More than 50k'], cbar=False, cmap='Blues')

#Turning off scientific notation
sns.heatmap(dnn_c_matrix,annot=True, fmt='g')

# ax.set_xlabel("Predicted result")
# ax.set_ylabel("Actual data")


# plt.show()
# plt.clf()

print(classification_report(y_validation, np.round(p_pred)))

"""Rewriting random forest evaluation for comapring with the Deep neural network"""

model_evaluation(model_RF,X_validaiton,y_validation)

"""

---



---



---


**We found out that Random forest still has the better performace with respect to accuracy, precision, recall and F1 values**"""